"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[271],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>k});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=r.createContext({}),d=function(e){var t=r.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=d(e.components);return r.createElement(p.Provider,{value:t},e.children)},s="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),s=d(n),u=a,k=s["".concat(p,".").concat(u)]||s[u]||m[u]||o;return n?r.createElement(k,i(i({ref:t},c),{},{components:n})):r.createElement(k,i({ref:t},c))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[s]="string"==typeof e?e:a,i[1]=l;for(var d=2;d<o;d++)i[d]=n[d];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8087:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var r=n(7462),a=(n(7294),n(3905));const o={sidebar_position:4},i="LAMM-Framework",l={unversionedId:"LAMM-Framework",id:"LAMM-Framework",title:"LAMM-Framework",description:"Installation",source:"@site/docs/LAMM-Framework.md",sourceDirName:".",slug:"/LAMM-Framework",permalink:"/docs/LAMM-Framework",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"LAMM-Dataset",permalink:"/docs/LAMM-Dataset"},next:{title:"LAMM-Benchmark",permalink:"/docs/LAMM-Benchmark"}},p={},d=[{value:"Installation",id:"installation",level:2},{value:"Data &amp; Model Preparation for Training",id:"data--model-preparation-for-training",level:2},{value:"Training",id:"training",level:2},{value:"2D Models Training",id:"2d-models-training",level:3},{value:"3D Models Training",id:"3d-models-training",level:3}],c={toc:d},s="wrapper";function m(e){let{components:t,...o}=e;return(0,a.kt)(s,(0,r.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"lamm-framework"},"LAMM-Framework"),(0,a.kt)("p",null,(0,a.kt)("img",{src:n(3125).Z,width:"1219",height:"263"})),(0,a.kt)("h2",{id:"installation"},"Installation"),(0,a.kt)("p",null,"Pre-requist Packages: ",(0,a.kt)("inlineCode",{parentName:"p"},"gcc <= 7.5.0; nvcc >= 11.1")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"    conda create -n lamm python=3.10 -y\n    conda activate lamm\n    # Choose different version of torch according to your \n    conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch\n")),(0,a.kt)("p",null,"Install required packages"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"    pip install -r requirements.txt\n\n    # Optional; For 3D experiments ONLY\n    cd src/model/EPCL/third_party/pointnet2/\n    python setup.py install\n    cd ../../utils/\n    pip install cython\n    python cython_compile.py build_ext --inplace\n")),(0,a.kt)("p",null,"Download required NLTK data"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"    import nltk\n    nltk.download('stopwords')\n    nltk.download('punkt')\n    nltk.download('wordnet')\n")),(0,a.kt)("h2",{id:"data--model-preparation-for-training"},"Data & Model Preparation for Training"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Data"),(0,a.kt)("p",{parentName:"li"},"  Follow ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/OpenLAMM/LAMM/tree/readme#download"},"Download")," to download and prepare the data for 2D and 3D tasks. Put downloaded data in ",(0,a.kt)("inlineCode",{parentName:"p"},"./data")," folder."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"\u251c\u2500\u2500 data\n    \u251c\u2500\u2500 2D_Instruct  \n    \u251c\u2500\u2500 3D_Instruct\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Language Model: Vicuna"),(0,a.kt)("p",{parentName:"li"},"  To prepare the pre-trained Vicuna model, please follow the instructions provided ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/lm-sys/FastChat/tree/main#vicuna-weights"},"Here"),". Put the downloaded model in the ",(0,a.kt)("inlineCode",{parentName:"p"},"./model_zoo/vicuna_ckpt")," folder.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"3D Encoder: EPCL"),(0,a.kt)("p",{parentName:"li"},"  Download Pre-trained EPCL model to tokenize point cloud from ",(0,a.kt)("a",{parentName:"p",href:"https://huggingface.co/openlamm/epcl_vit-L_256tokens/tree/main"},"Here"),". Put the downloaded models in the ",(0,a.kt)("inlineCode",{parentName:"p"},"./ckpt")," folder."))),(0,a.kt)("h2",{id:"training"},"Training"),(0,a.kt)("h3",{id:"2d-models-training"},"2D Models Training"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Bash"},"cd src\nsh scripts/train_lamm2d.sh\nor\nsh scripts/train_lamm2d_slurm.sh       # for slurm\n")),(0,a.kt)("h3",{id:"3d-models-training"},"3D Models Training"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Bash"},"cd src\nsh scripts/train_lamm3d.sh\nor\nsh scripts/train_lamm3d_slurm.sh       # for slurm\n")),(0,a.kt)("p",null,"You need to dive into scripts to change data path and other hyper-parameters. "),(0,a.kt)("p",null,"For your reference, GPU memory consumption for different models are shown as follows"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:"center"},"Model Size"),(0,a.kt)("th",{parentName:"tr",align:"center"},"Sample Num/GPU"),(0,a.kt)("th",{parentName:"tr",align:"center"},"GPU Memory"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"center"},"Vicuna_v0_7B"),(0,a.kt)("td",{parentName:"tr",align:"center"},"1"),(0,a.kt)("td",{parentName:"tr",align:"center"},"~30GB")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"center"},"Vicuna_v0_7B"),(0,a.kt)("td",{parentName:"tr",align:"center"},"2"),(0,a.kt)("td",{parentName:"tr",align:"center"},"~46GB")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"center"},"Vicuna_v0_13B"),(0,a.kt)("td",{parentName:"tr",align:"center"},"1"),(0,a.kt)("td",{parentName:"tr",align:"center"},"~53GB")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"center"},"Vicuna_v0_13B"),(0,a.kt)("td",{parentName:"tr",align:"center"},"2"),(0,a.kt)("td",{parentName:"tr",align:"center"},"~70GB")))))}m.isMDXComponent=!0},3125:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/LAMM-Framework-38fd384d0dbafa946d8253b9735575b1.png"}}]);