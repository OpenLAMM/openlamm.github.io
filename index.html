<!doctype html>
<html lang="en" dir="ltr" class="plugin-pages plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">LAMM</title><meta data-rh="true" property="og:title" content="LAMM"><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://openlamm.github.io/logo/LAMM-logo.png"><meta data-rh="true" name="twitter:image" content="https://openlamm.github.io/logo/LAMM-logo.png"><meta data-rh="true" property="og:url" content="https://openlamm.github.io/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="description" content="Real-time audio &amp; video SDKs, ready to launch üöÄ"><meta data-rh="true" property="og:description" content="Real-time audio &amp; video SDKs, ready to launch üöÄ"><link data-rh="true" rel="icon" href="/logo/LAMM-logo.png"><link data-rh="true" rel="canonical" href="https://openlamm.github.io/"><link data-rh="true" rel="alternate" href="https://openlamm.github.io/" hreflang="en"><link data-rh="true" rel="alternate" href="https://openlamm.github.io/" hreflang="x-default"><link data-rh="true" rel="prefetch" href="/assets/css/elements.min.css"><script data-rh="true">function maybeInsertBanner(){window.__DOCUSAURUS_INSERT_BASEURL_BANNER&&insertBanner()}function insertBanner(){var n=document.getElementById("__docusaurus-base-url-issue-banner-container");if(n){n.innerHTML='\n<div id="__docusaurus-base-url-issue-banner" style="border: thick solid red; background-color: rgb(255, 230, 179); margin: 20px; padding: 20px; font-size: 20px;">\n   <p style="font-weight: bold; font-size: 30px;">Your Docusaurus site did not load properly.</p>\n   <p>A very common reason is a wrong site <a href="https://docusaurus.io/docs/docusaurus.config.js/#baseUrl" style="font-weight: bold;">baseUrl configuration</a>.</p>\n   <p>Current configured baseUrl = <span style="font-weight: bold; color: red;">/</span>  (default value)</p>\n   <p>We suggest trying baseUrl = <span id="__docusaurus-base-url-issue-banner-suggestion-container" style="font-weight: bold; color: green;"></span></p>\n</div>\n';var e=document.getElementById("__docusaurus-base-url-issue-banner-suggestion-container"),s=window.location.pathname,r="/"===s.substr(-1)?s:s+"/";e.innerHTML=r}}window.__DOCUSAURUS_INSERT_BASEURL_BANNER=!0,document.addEventListener("DOMContentLoaded",maybeInsertBanner)</script><link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-5FDFFSS",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>





<script src="https://cdn.statuspage.io/se-v2.js"></script><link rel="stylesheet" href="/assets/css/styles.a4ef9c45.css">
<link rel="preload" href="/assets/js/runtime~main.32dfc798.js" as="script">
<link rel="preload" href="/assets/js/main.a70bc8d0.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5FDFFSS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div id="__docusaurus-base-url-issue-banner-container"></div><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/logo/LAMM-logo-light.png" alt="LAMM" class="themedImage_ToTc themedImage--light_HNdA" height="60px"><img src="/logo/LAMM-logo-dark.png" alt="LAMM" class="themedImage_ToTc themedImage--dark_i4oU" height="60px"></div></a><a class="navbar__item navbar__link" href="/tutorial">Tutorial</a><a class="navbar__item navbar__link" href="/datasets">Datasets</a><a class="navbar__item navbar__link" href="/model_system_card">Models</a><a class="navbar__item navbar__link" href="/Leaderboards">Leaderboards</a><a class="navbar__item navbar__link" href="/Team">Team</a><a href="https://github.com/OpenGVLab/LAMM" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 homepage flex flex-col"><div class="noise-bg homepage-bg" style="height:0px"></div><h2 class="homepage-title mb-8 max-w-5xl px-4 pt-16 text-center font-jakarta text-5xl font-bold">LAMM: Multi-Modal Large Language Models and Applications as AI Agents</h2><div class="homepage-content"><section class="no-underline-links lg:py-0" id="HeroSection"><div class="flex flex-col items-center justify-between py-14 px-4"><p class="max-w-5xl font-jakarta text-xl"><b>LAMM</b> (pronounced as /l√¶m/, means cute lamb to show appreciation to LLaMA), is a growing open-source community aimed at helping researchers and developers quickly train and evaluate Multi-modal Large Language Models (MLLM), and futher build multi-modal AI agents capable of bridging the gap between ideas and execution, enabling seamless interaction between humans and AI machines. <br> <br>As one of the very first open-source endeavors in the MLLM field, our goal is to create an ecosystem where every researcher and developer can apply, study, and even contribute. We work on various aspects including MLLM datasets, frameworks, benchmarks, optimizations, and applications as AI Agents. As a fully transparent open-source community, any form of collaboration is welcome! <br>Please feel free to contact<!-- --> <a href="mailto: zyin7056@uni.sydney.edu.au">Zhenfei Yin</a> or<!-- --> <a href="mailto: shaojing@pjlab.org.cn">Jing Shao</a>!</p></div></section><div class="swiper-container img-swiper lg"><div class="swiper-button-prev"></div><div class="swiper-button-next"></div><div class="swiper-pagination"></div><div class="swiper-wrapper"><div class="swiper-slide swiper-slide-duplicate" data-swiper-slide-index="2"><img src="/img/img.JPEG"></div><div class="swiper-slide" data-swiper-slide-index="0"><iframe width="100%" height="450" src="https://www.youtube.com/embed/2kRsJYGFiEw?si=hXC1xpHi9GJHUsoX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><div class="swiper-slide" data-swiper-slide-index="1"><iframe width="100%" height="450" src="https://www.youtube.com/embed/M7XlIe8hhPk" title="Introducing LAMM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><div class="swiper-slide" data-swiper-slide-index="2"><img src="/img/img.JPEG"></div><div class="swiper-slide swiper-slide-duplicate" data-swiper-slide-index="0"><iframe width="100%" height="450" src="https://www.youtube.com/embed/2kRsJYGFiEw?si=hXC1xpHi9GJHUsoX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div></div></div><div class="pt-20"></div><section class="mx-auto grid w-full max-w-5xl grid-cols-1 grid-rows-2 gap-6 px-4 md:grid-cols-2"><a style="border-width:1px" class="group relative cursor-pointer overflow-clip rounded-3xl from-primary/30 via-transparent to-transparent text-black transition-all hover:bg-gradient-to-tr hover:text-primary hover:no-underline dark:text-white border-secondary-700 bg-secondary-900 hover:!border-primary dark:border-secondary-800" href="/tutorial"><div class="p-6 !pb-0"><h3 class="mb-1.5 flex items-center gap-3 font-jakarta group-hover:text-primary"><svg class="h-7 w-7 ___12fm75w f1w7gpdv fez10in fg4l7m0" fill="currentColor" aria-hidden="true" width="20" height="20" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M4 4v12c0 1.1.9 2 2 2h9.5a.5.5 0 0 0 0-1H6a1 1 0 0 1-1-1h10a1 1 0 0 0 1-1V4a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2Zm10-1a1 1 0 0 1 1 1v11H5V4a1 1 0 0 1 1-1h8Zm-3.25 2.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm-.25 6.75a.5.5 0 0 1-1 0v-4a.5.5 0 0 1 1 0v4Z" fill="currentColor"></path></svg><div>Tutorial</div></h3><p class="mb-0 text-sm text-zinc-400">Learn how to prepare the dataset, model, environment, and start training and evaluation.</p></div><div class="p-6 !pb-0"></div></a><a style="border-width:1px" class="group relative cursor-pointer overflow-clip rounded-3xl from-primary/30 via-transparent to-transparent text-black transition-all hover:bg-gradient-to-tr hover:text-primary hover:no-underline dark:text-white border-secondary-700 bg-secondary-900 hover:!border-primary dark:border-secondary-800" href="/datasets"><div class="p-6 !pb-0"><h3 class="mb-1.5 flex items-center gap-3 font-jakarta group-hover:text-primary"><svg class="h-7 w-7 ___12fm75w f1w7gpdv fez10in fg4l7m0" fill="currentColor" aria-hidden="true" width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 6c0-.7.32-1.3.77-1.78a5.61 5.61 0 0 1 1.8-1.2A13.65 13.65 0 0 1 12 2c2.08 0 4 .38 5.43 1.02.72.32 1.34.72 1.8 1.2.45.49.77 1.09.77 1.78v12c0 .7-.32 1.3-.77 1.78-.46.48-1.08.88-1.8 1.2A13.65 13.65 0 0 1 12 22c-2.08 0-4-.38-5.43-1.02a5.61 5.61 0 0 1-1.8-1.2A2.6 2.6 0 0 1 4 18V6Zm1.5 0c0 .2.09.46.37.75.27.3.71.6 1.31.86 1.2.54 2.9.89 4.82.89 1.92 0 3.62-.35 4.82-.89.6-.26 1.04-.56 1.31-.86.28-.3.37-.54.37-.75 0-.2-.09-.46-.37-.75-.27-.3-.71-.6-1.31-.86-1.2-.54-2.9-.89-4.82-.89-1.92 0-3.62.35-4.82.89-.6.26-1.04.56-1.31.86-.28.3-.37.54-.37.75Zm13 2.4a6.8 6.8 0 0 1-1.07.58A13.65 13.65 0 0 1 12 10c-2.08 0-4-.38-5.43-1.02A6.8 6.8 0 0 1 5.5 8.4V18c0 .2.09.46.37.75.27.3.71.6 1.31.86 1.2.54 2.9.89 4.82.89 1.92 0 3.62-.35 4.82-.89.6-.26 1.04-.56 1.31-.86.28-.3.37-.54.37-.75V8.4Z" fill="currentColor"></path></svg><div>Datasets</div></h3><p class="mb-0 text-sm text-zinc-400">Download the datasets.</p></div><div class="p-6 !pb-0"></div></a><a style="border-width:1px" class="group relative cursor-pointer overflow-clip rounded-3xl from-primary/30 via-transparent to-transparent text-black transition-all hover:bg-gradient-to-tr hover:text-primary hover:no-underline dark:text-white border-secondary-700 bg-secondary-900 hover:!border-primary dark:border-secondary-800" href="/Model_system_card"><div class="p-6 !pb-0"><h3 class="mb-1.5 flex items-center gap-3 font-jakarta group-hover:text-primary"><svg class="h-7 w-7 ___12fm75w f1w7gpdv fez10in fg4l7m0" fill="currentColor" aria-hidden="true" width="20" height="20" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M13.5 8.5a1 1 0 1 0-2 0 1 1 0 0 0 2 0Zm-5 0a1 1 0 1 0-2 0 1 1 0 0 0 2 0Zm-.03 4.55a.5.5 0 1 0-.44.9c.58.29 1.28.43 1.97.43s1.39-.14 1.97-.43a.5.5 0 1 0-.44-.9c-.42.21-.97.32-1.53.32a3.5 3.5 0 0 1-1.53-.32ZM18 10a8 8 0 1 0-16 0 8 8 0 0 0 16 0ZM3 10a7 7 0 1 1 14 0 7 7 0 0 1-14 0Z" fill="currentColor"></path></svg><div>Models</div></h3><p class="mb-0 text-sm text-zinc-400">Use LAMM Models.</p></div><div class="p-6 !pb-0"></div></a><a style="border-width:1px" class="group relative cursor-pointer overflow-clip rounded-3xl from-primary/30 via-transparent to-transparent text-black transition-all hover:bg-gradient-to-tr hover:text-primary hover:no-underline dark:text-white border-secondary-700 bg-secondary-900 hover:!border-primary dark:border-secondary-800" href="/Leaderboards"><div class="p-6 !pb-0"><h3 class="mb-1.5 flex items-center gap-3 font-jakarta group-hover:text-primary"><svg class="h-7 w-7 ___12fm75w f1w7gpdv fez10in fg4l7m0" fill="currentColor" aria-hidden="true" width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 5.75c0-.41.34-.75.75-.75h15.5a.75.75 0 0 1 0 1.5H2.75A.75.75 0 0 1 2 5.75Zm0 12c0-.41.34-.75.75-.75h12.5a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1-.75-.75ZM2.75 11a.75.75 0 0 0 0 1.5h18.5a.75.75 0 0 0 0-1.5H2.75Z" fill="currentColor"></path></svg><div>Leaderboards</div></h3><p class="mb-0 text-sm text-zinc-400">View the leaderboards of multimodal large language models.</p></div><div class="p-6 !pb-0"></div></a></section><section class="no-underline-links news-wrap mx-auto mt-14 flex w-full max-w-5xl flex-col p-4 py-0 md:flex-row md:gap-0"><div class="flex-1"><div class="mb-8 flex items-center justify-between"><h3 class="m-0">News</h3></div><div class="flex flex-col gap-4"><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">üìÜ [<!-- -->2023-11<!-- -->]</h4><p class="mb-0 text-lg text-text-400">1. <a href="https://arxiv.org/abs/2311.02684" target="_blank">Octavius</a> & <a href="https://arxiv.org/abs/2311.02692" target="_blank">ChEF</a> released on Arxiv!</p><p class="mb-0 text-lg text-text-400">2. Camera ready version of LAMM is available on <a href="https://arxiv.org/abs/2306.06687" target="_blank">Arxiv</a>.</p></div><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">üìÜ [<!-- -->2023-10<!-- -->]</h4><p class="mb-0 text-lg text-text-400">1. LAMM is accepted by NeurIPS2023 Datasets & Benchmark Track! See you in December!</p></div><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">üìÜ [<!-- -->2023-09<!-- -->]</h4><p class="mb-0 text-lg text-text-400">1. Light training framework for V100 or RTX3090 is available! LLaMA2-based finetuning is also online.</p><p class="mb-0 text-lg text-text-400">2. Our demo moved to <a href="https://openxlab.org.cn/apps/detail/LAMM/LAMM" target="_blank">OpenXLab</a>.</p></div><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">üìÜ [<!-- -->2023-07<!-- -->]</h4><p class="mb-0 text-lg text-text-400">1.  Checkpoints & Leaderboard of LAMM on huggingface updated on new code base.</p><p class="mb-0 text-lg text-text-400">2.  Evaluation code for both 2D and 3D tasks are ready.</p><p class="mb-0 text-lg text-text-400">3.  Command line demo tools updated.</p></div><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">üìÜ [<!-- -->2023-06<!-- -->]</h4><p class="mb-0 text-lg text-text-400">1. Watch demo video for LAMM at <a href="https://www.youtube.com/watch?v=M7XlIe8hhPk" target="_blank">YouTube</a> or <a href="https://www.bilibili.com/video/BV1kN411D7kt/" target="_blank">Bilibili</a>!</p><p class="mb-0 text-lg text-text-400">2. Full paper with Appendix is available on <a href="https://arxiv.org/abs/2306.06687" target="_blank">Arxiv</a>.</p><p class="mb-0 text-lg text-text-400">3. LAMM dataset released on <a href="https://huggingface.co/datasets/openlamm/LAMM_Dataset" target="_blank">Huggingface</a> & <a href="https://opendatalab.com/LAMM/LAMM" target="_blank">OpenDataLab</a> for Research community!</p><p class="mb-0 text-lg text-text-400">4. LAMM code is available for Research community!</p></div></div></div></section><section class="no-underline-links my-10 mx-auto flex w-full max-w-5xl flex-col gap-10 p-4 py-0 md:flex-row md:gap-0"><div class="flex-1"><div class="mb-8 flex items-center justify-between"><h3 class="m-0">Publications</h3></div><div class="flex flex-col gap-4"><a class="group flex cursor-pointer items-start gap-2 rounded-lg border-2 border-transparent p-3 text-inherit transition-colors hover:border-primary hover:text-primary" href="/paper_list/LAMM"><img src="/img/LAMM.png" class="paper_image"><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark</h4><p class="mb-0 text-sm text-text-400">Zhenfei Yin*, Jiong Wang*, JianJian Cao*, Zhelun Shi*,  Dingning Liu, Mukai Li, Lu Sheng, Lei Bai‚Ä†, Xiaoshui Huang, Zhiyong Wang, Jing Shao‚Ä†, Wanli Ouyang</p><i class="mb-0 text-sm text-text-400">NeurIPS, 2023, Datasets and Benchmarks Track</i></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="ml-auto h-5 w-5 self-center opacity-0 transition-opacity group-hover:opacity-100"><polyline points="9 18 15 12 9 6"></polyline></svg></a></div></div></section><section class="no-underline-links my-10 mt-2 mx-auto flex w-full max-w-5xl flex-col gap-10 p-4 py-0 md:flex-row md:gap-0"><div class="flex-1"><div class="mb-8 flex items-center justify-between"><h3 class="m-0">Preprints</h3></div><div class="flex flex-col gap-4"><a class="group flex cursor-pointer items-start gap-2 rounded-lg border-2 border-transparent p-3 text-inherit transition-colors hover:border-primary hover:text-primary" href="/paper_list/ChEF"><img src="/img/ChEF.png" class="paper_image"><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models</h4><p class="mb-0 text-sm text-text-400">Zhelun Shi*, Zhipin Wang*, Hongxing Fan*, Zhenfei Yin, Lu Sheng‚Ä†, Yu Qiao, Jing Shao‚Ä†</p><i class="mb-0 text-sm text-text-400">Arxiv, 2023</i></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="ml-auto h-5 w-5 self-center opacity-0 transition-opacity group-hover:opacity-100"><polyline points="9 18 15 12 9 6"></polyline></svg></a><a class="group flex cursor-pointer items-start gap-2 rounded-lg border-2 border-transparent p-3 text-inherit transition-colors hover:border-primary hover:text-primary" href="/paper_list/Octavius"><img src="/logo/Octavius_arch.png" class="paper_image"><div class="flex flex-col p-1"><h4 class="mb-1 font-semibold">Octavius: Mitigating Task Interference in MLLMs via MoE</h4><p class="mb-0 text-sm text-text-400">Zeren Chen*, Ziqin Wang*, Zhen Wang*, Huayang Liu, Zhenfei Yin, Si Liu, Lu Sheng‚Ä†, Wanli Ouyang, Yu Qiao, Jing Shao‚Ä†</p><i class="mb-0 text-sm text-text-400">Arxiv, 2023</i></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="ml-auto h-5 w-5 self-center opacity-0 transition-opacity group-hover:opacity-100"><polyline points="9 18 15 12 9 6"></polyline></svg></a></div></div></section></div><section class="no-underline-links join-lamm-wrap"><hr class="my-2 !bg-gray-300"><div class="mx-auto flex w-full flex-col items-center justify-center px-4 pt-4"><h2 class="text-3xl">Join <span class="text-primary-100">LAMM</span></h2><p class="mb-10 text-zinc-500">Engage with our ever-growing community to get the latest updates, product support, and more.</p><div class="mx-auto mb-2 flex flex-wrap -space-x-1.5"><div class="group relative"><a href="https://github.com/wangjiongw"><img src="https://github.com/wangjiongw.png?size=60" alt="User wangjiongw" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/Coach257"><img src="https://github.com/Coach257.png?size=60" alt="User Coach257" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/Zx55"><img src="https://github.com/Zx55.png?size=60" alt="User Zx55" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/double125"><img src="https://github.com/double125.png?size=60" alt="User double125" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/lnbxldn"><img src="https://github.com/lnbxldn.png?size=60" alt="User lnbxldn" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/wtt0213"><img src="https://github.com/wtt0213.png?size=60" alt="User wtt0213" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/lighten001"><img src="https://github.com/lighten001.png?size=60" alt="User lighten001" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/fanhongxing"><img src="https://github.com/fanhongxing.png?size=60" alt="User fanhongxing" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/Puck-U"><img src="https://github.com/Puck-U.png?size=60" alt="User Puck-U" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/Zhoues"><img src="https://github.com/Zhoues.png?size=60" alt="User Zhoues" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/yinzhenfei"><img src="https://github.com/yinzhenfei.png?size=60" alt="User yinzhenfei" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div><div class="group relative"><a href="https://github.com/dhuip"><img src="https://github.com/dhuip.png?size=60" alt="User dhuip" loading="lazy" class="h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"></a></div></div></div></section><div class="mx-auto flex items-center w-full max-w-[1080px] flex-col px-6 py-12"><div class="flex flex-col gap-6 lg:flex-row lg:items-center lg:justify-between lg:gap-0"><div class="flex items-center gap-4"><div class="flex flex-wrap gap-2 text-sm text-gray-500"><span class="text-inherit">¬© <!-- -->2023<!-- --> LAMM. Built with Dyte.</span></div></div></div></div></div></div>
<script src="/assets/js/runtime~main.32dfc798.js"></script>
<script src="/assets/js/main.a70bc8d0.js"></script>
</body>
</html>