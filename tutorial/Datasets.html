<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-tutorial docs-doc-id-Datasets/datasets">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Datasets | LAMM</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://openlamm.github.io/logo/LAMM-logo.png"><meta data-rh="true" name="twitter:image" content="https://openlamm.github.io/logo/LAMM-logo.png"><meta data-rh="true" property="og:url" content="https://openlamm.github.io/tutorial/Datasets"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-tutorial-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-tutorial-current"><meta data-rh="true" property="og:title" content="Datasets | LAMM"><meta data-rh="true" name="description" content="We divide the dataset into two categories: the instruction dataset and the benchmark dataset."><meta data-rh="true" property="og:description" content="We divide the dataset into two categories: the instruction dataset and the benchmark dataset."><link data-rh="true" rel="icon" href="/logo/LAMM-logo.png"><link data-rh="true" rel="canonical" href="https://openlamm.github.io/tutorial/Datasets"><link data-rh="true" rel="alternate" href="https://openlamm.github.io/tutorial/Datasets" hreflang="en"><link data-rh="true" rel="alternate" href="https://openlamm.github.io/tutorial/Datasets" hreflang="x-default"><link data-rh="true" rel="stylesheet" href="/assets/css/docsly.min.css"><link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-5FDFFSS",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>





<script src="https://cdn.statuspage.io/se-v2.js"></script><link rel="stylesheet" href="/assets/css/styles.959e90f6.css">
<link rel="preload" href="/assets/js/runtime~main.7f68de47.js" as="script">
<link rel="preload" href="/assets/js/main.d6ae70d1.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5FDFFSS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/logo/LAMM-logo-light.png" alt="LAMM" class="themedImage_ToTc themedImage--light_HNdA" height="60px"><img src="/logo/LAMM-logo-dark.png" alt="LAMM" class="themedImage_ToTc themedImage--dark_i4oU" height="60px"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/tutorial">Tutorial</a><a class="navbar__item navbar__link" href="/datasets">Datasets</a><a class="navbar__item navbar__link" href="/model_system_card">Models</a><a class="navbar__item navbar__link" href="/Leaderboards">Leaderboards</a><a class="navbar__item navbar__link" href="/Team">Team</a><a href="https://github.com/OpenGVLab/LAMM" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_mhZE"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item guide_sidebar_index"><a class="menu__link" href="/tutorial">Tutorial</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" aria-expanded="true" href="/tutorial/Datasets">Datasets</a><button aria-label="Toggle the collapsible sidebar category &#x27;Datasets&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorial/Datasets/instruction">Instruction Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorial/Datasets/benchmark">Benchmarking</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/tutorial/installation">Installation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/tutorial/Training">Training</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/tutorial/Benchmark/default">Benchmark</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/tutorial/citations">Citation</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Datasets</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Datasets</h1></header><p>We divide the dataset into two categories: the instruction dataset and the benchmark dataset.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="instruction-data">Instruction Data<a href="#instruction-data" class="hash-link" aria-label="Direct link to Instruction Data" title="Direct link to Instruction Data">​</a></h2><p><img loading="lazy" alt="LAMM Dataset" src="/assets/images/LAMM-Dataset-c2980e90c273a8844e235fc9cf535d2e.png" width="1948" height="1850" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lamm">LAMM<a href="#lamm" class="hash-link" aria-label="Direct link to LAMM" title="Direct link to LAMM">​</a></h3><p>LAMM-Dataset is a comprehensive multi-modal instruction tuning dataset, which contains 186K language-image instruction-response pairs, and 10K lanuage-3D instruction-response pairs.In LAMM-Dataset, the instruction-response pairs are gathered from 8 image datasets and 4 point cloud datasets. Here we design four type of multi-modal instruction-response pairs,</p><ul><li>C1: n-round daily dialogue focuses on multi-modal daily conversations.</li><li>C2: n-round factual knowledge dialogue aims at factual knowledge reasoning.</li><li>C3: 1-round detailed description aims to elaborate images and 3D scenes in texts.</li><li>C4: 1-round visual task dialogue transfers various vision tasks into instruction-response pairs, aiming at enhancing generalizability towards domain tasks in other modalities.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="octavius">Octavius<a href="#octavius" class="hash-link" aria-label="Direct link to Octavius" title="Direct link to Octavius">​</a></h3><p>Octavius additionally integrates generated COCO detection instruction data into original LAMM2D-Dataset as supplement in instruction tuning. For 3D point cloud data, Octavius constructs an novel instruction dataset based on the ScanRefer dataset that includes captioning, VQA and classification tasks, referred to as “Scan2Inst”, for 3D instruction tuning.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-data">Benchmark Data<a href="#benchmark-data" class="hash-link" aria-label="Direct link to Benchmark Data" title="Direct link to Benchmark Data">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lamm-1">LAMM<a href="#lamm-1" class="hash-link" aria-label="Direct link to LAMM" title="Direct link to LAMM">​</a></h3><p>LAMM-Benchmark evaluates 9 common image tasks, using a total of 11 datasets with over 62,439 samples, and 3 common point cloud tasks, by utilizing 3 datasets with over 12,788 data samples, while existing works only provide quantitative results on fine-tuning and evaluating specific datasets such as ScienceQA, and most works only conduct demonstration or user studies.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="chef">ChEF<a href="#chef" class="hash-link" aria-label="Direct link to ChEF" title="Direct link to ChEF">​</a></h3><p>ChEF evaluates MLLMs across 9 datasets including including CIFAR-10 for classification, Omnibenchmark for fine-grained classification, VOC2012 for object detection, FSC147 for object counting, Flickr30k for image captioning and ScienceQA for multimodal question-answering. We also evaluate the MLLMs on several multi-task datasets including MME, MMbench, and Seedbench. Based on ScienceQA and MMbench, we build ScienceQA_C and MMbench_C dataset by adding corruptions to images and text, to evaluate MLLM&#x27;s Robustness, which is one of the six desiderata.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/tutorial"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Tutorial</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/tutorial/Datasets/instruction"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Instruction Tuning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#instruction-data" class="table-of-contents__link toc-highlight">Instruction Data</a><ul><li><a href="#lamm" class="table-of-contents__link toc-highlight">LAMM</a></li><li><a href="#octavius" class="table-of-contents__link toc-highlight">Octavius</a></li></ul></li><li><a href="#benchmark-data" class="table-of-contents__link toc-highlight">Benchmark Data</a><ul><li><a href="#lamm-1" class="table-of-contents__link toc-highlight">LAMM</a></li><li><a href="#chef" class="table-of-contents__link toc-highlight">ChEF</a></li></ul></li></ul></div></div></div></div></main></div></div><div class="mx-auto flex items-center w-full max-w-[1080px] flex-col px-6 py-12"><div class="flex flex-col gap-6 lg:flex-row lg:items-center lg:justify-between lg:gap-0"><div class="flex items-center gap-4"><div class="flex flex-wrap gap-2 text-sm text-gray-500"><span class="text-inherit">© <!-- -->2024<!-- --> LAMM. Built with Dyte.</span></div></div></div></div></div>
<script src="/assets/js/runtime~main.7f68de47.js"></script>
<script src="/assets/js/main.d6ae70d1.js"></script>
</body>
</html>