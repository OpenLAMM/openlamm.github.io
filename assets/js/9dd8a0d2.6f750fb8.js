"use strict";(self.webpackChunkdyte_docs=self.webpackChunkdyte_docs||[]).push([[7054],{6953:(e,t,a)=>{a.d(t,{T:()=>o,Z:()=>l});var n=a(7294);const r=["wangjiongw","Coach257","Zx55","double125","lnbxldn","wtt0213","lighten001","fanhongxing","Puck-U","Zhoues","yinzhenfei"];function l(){const[e,t]=(0,n.useState)(null),a=()=>{t(null)};return n.createElement("section",{className:"no-underline-links"},n.createElement("hr",{className:"my-2 !bg-gray-300"}),n.createElement("div",{className:"mx-auto flex w-full flex-col items-center justify-center px-4 pt-4"},n.createElement("h2",{className:"text-3xl"},"Join ",n.createElement("span",{className:"text-primary-100"},"LAMM")),n.createElement("p",{className:"mb-10 text-zinc-500"},"Engage with our ever-growing community to get the latest updates, product support, and more."),n.createElement("div",{className:"mx-auto mb-2 flex flex-wrap -space-x-1.5"},r.map((r=>n.createElement("div",{className:"group relative",onMouseEnter:()=>{t(r)},onMouseLeave:a},n.createElement("a",{href:`https://github.com/${r}`},e===r&&n.createElement("div",{className:"tooltip"},r),n.createElement("img",{key:r,src:`https://github.com/${r}.png?size=60`,alt:`User ${r}`,loading:"lazy",className:"h-6 w-6 rounded-full border-2 border-solid border-white transition group-hover:-translate-y-2 group-hover:scale-150 lg:h-12 lg:w-12"}))))))))}const o=()=>r},5494:(e,t,a)=>{a.r(t),a.d(t,{default:()=>I});var n=a(7294),r=a(1476),l=a(1984),o=a(254),i=a(5607),c=a(424),s=a(2440),m=a(6010);const u=function(){return n.createElement("div",{className:"video-section",style:{display:"flex",justifyContent:"center"}},n.createElement("iframe",{width:"1070",height:"602",src:"https://www.youtube.com/embed/M7XlIe8hhPk",title:"Introducing LAMM",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0}))};function p(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function g(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}const d=[{title:"Tutorial",link:"/tutorial",icon:o.Ks1,lightImage:"",darkImage:"",text:"Learn how to prepare the dataset, model, environment, and start training and evaluation."},{title:"Datasets",link:"/datasets",icon:i.$3m,lightImage:"",darkImage:"",text:"Download the datasets."},{title:"Models",link:"/Model_system_card",icon:c.eyU,lightImage:"",darkImage:"",text:"Use LAMM Models."},{title:"Leaderboards",beta:!1,link:"/Leaderboards",icon:s._2W,lightImage:"",darkImage:"",text:"View the leaderboards of multimodal large language models."}];function b({link:e,title:t,icon:a,text:r,lightImage:o,darkImage:i,beta:c}){return n.createElement(l.Z,{to:e,style:{borderWidth:"1px"},className:(0,m.Z)("group relative cursor-pointer overflow-clip rounded-3xl from-primary/30 via-transparent to-transparent text-black transition-all hover:bg-gradient-to-tr hover:text-primary hover:no-underline dark:text-white","border-secondary-700 bg-secondary-900 hover:!border-primary dark:border-secondary-800")},n.createElement("div",{className:"p-6 !pb-0"},n.createElement("h3",{className:"mb-1.5 flex items-center gap-3 font-jakarta group-hover:text-primary"},n.createElement(a,{className:"h-7 w-7"}),n.createElement("div",null,t,c&&n.createElement("span",{className:"font-normal text-text-400"}," (Beta)"))),n.createElement("p",{className:"mb-0 text-sm text-zinc-400"},r)),n.createElement("div",{className:"p-6 !pb-0"}))}function f(){return n.createElement(n.Fragment,null,n.createElement("section",{className:"noise-bg no-underline-links px-4 pt-16 lg:py-0"},n.createElement("div",{className:"flex flex-col items-center justify-between py-14"},n.createElement("h2",{className:"mb-8 max-w-5xl text-center font-jakarta text-5xl font-bold"},"LAMM: Language Assisted Multimodal Models and their Applications"),n.createElement("p",{className:"max-w-5xl font-jakarta text-xl"},"LAMM (pronounced as /l\xe6m/, means cute lamb to show appreciation to LLaMA), is a growing open-source community aimed at helping researchers and developers quickly train and evaluate Multi-modal Large Language Models (MLLM), and futher build multi-modal AI agents capable of bridging the gap between ideas and execution, enabling seamless interaction between humans and AI machines."))),n.createElement(u,null),n.createElement("div",{className:"pt-20"}),n.createElement("section",{className:"mx-auto grid w-full max-w-5xl grid-cols-1 grid-rows-2 gap-6 px-4 md:grid-cols-2"},d.map((e=>n.createElement(b,g(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){p(e,t,a[t])}))}return e}({},e),{key:e.title}))))))}var h=a(6953),y=a(232),x=a(1098),w=a(628);function v(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function E(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){v(e,t,a[t])}))}return e}function O(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}const k=[{id:"LAMM",title:"LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark",image:"/img/LAMM.png",author:"Zhenfei Yin*, Jiong Wang*, JianJian Cao*, Zhelun Shi*,  Dingning Liu, Mukai Li, Lu Sheng, Xiaoshui Huang, Lei Bai\u2020, Zhiyong Wang, Wanli Ouyang, Jing Shao\u2020",pub:"NIPS, 2023, Datasets and Benchmarks Track",link:"https://arxiv.org/abs/2306.06687"}],M=[{id:"ChEF",title:"ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models",image:"/img/ChEF.png",author:"Zhelun Shi*, Zhipin Wang*, Hongxing Fan*, Zhenfei Yin, Lu Sheng\u2020, Yu Qiao, Jing Shao\u2020",pub:"Arxiv, 2023",link:"https://arxiv.org/abs/2306.06687"},{id:"Octavius",title:"Octavius: Mitigating Task Interference in MLLMs via MoE",image:"/logo/Octavius_arch.png",author:"Zeren Chen*, Ziqin Wang*, Zhen Wang*, Huayang Liu, Zhenfei Yin, Si Liu, Lu Sheng\u2020, Wanli Ouyang, Yu Qiao, Jing Shao\u2020",pub:"Arxiv, 2023",link:"https://arxiv.org/abs/2306.06687"}];function j({id:e,title:t,image:a,author:r,pub:o,link:i}){return n.createElement(l.Z,{to:"/paper_list/"+e,className:"group flex cursor-pointer items-start gap-2 rounded-lg border-2 border-transparent p-3 text-inherit transition-colors hover:border-primary hover:text-primary"},n.createElement("img",{src:a,className:"paper_image"}),n.createElement("div",{className:"flex flex-col p-1"},n.createElement("h4",{className:"mb-1 font-semibold"},t),n.createElement("p",{className:"mb-0 text-sm text-text-400"},r),n.createElement("i",{className:"mb-0 text-sm text-text-400"},o)),n.createElement(w.Z,{className:"ml-auto h-5 w-5 self-center opacity-0 transition-opacity group-hover:opacity-100"}))}function N(){return n.createElement("section",{className:"no-underline-links my-10 mx-auto flex w-full max-w-5xl flex-col gap-10 p-4 py-0 md:flex-row md:gap-0"},n.createElement("div",{className:"flex-1"},n.createElement("div",{className:"mb-8 flex items-center justify-between"},n.createElement("h3",{className:"m-0"},"Publications")),n.createElement("div",{className:"flex flex-col gap-4"},k.map((e=>n.createElement(j,O(E({},e),{key:e.title})))))))}function L(){return n.createElement("section",{className:"no-underline-links my-10 mt-2 mx-auto flex w-full max-w-5xl flex-col gap-10 p-4 py-0 md:flex-row md:gap-0"},n.createElement("div",{className:"flex-1"},n.createElement("div",{className:"mb-8 flex items-center justify-between"},n.createElement("h3",{className:"m-0"},"Preprints")),n.createElement("div",{className:"flex flex-col gap-4"},M.map((e=>n.createElement(j,O(E({},e),{key:e.title})))))))}function P(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function A(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}const D=[{month:"2023-09",content:["1. LAMM is accepted by NeurIPS2023 Datasets & Benchmark Track! See you in December!","2. Training LAMM on V100 or RTX3090 is available! Finetuning LLaMA2 is online.",'3. Our demo moved to <a href="https://openxlab.org.cn/apps/detail/LAMM/LAMM" target="_blank">OpenXLab</a>.']},{month:"2023-07",content:["1.  Checkpoints & Leaderboard of LAMM on huggingface updated on new code base.","2.  Evaluation code for both 2D and 3D tasks are ready.","3.  Command line demo tools updated."]},{month:"2023-06",content:['1. Watch demo video for LAMM at <a href="https://www.youtube.com/watch?v=M7XlIe8hhPk" target="_blank">YouTube</a> or <a href="https://www.bilibili.com/video/BV1kN411D7kt/" target="_blank">Bilibili</a>!','2. Full paper with Appendix is available on <a href="https://arxiv.org/abs/2306.06687" target="_blank">Arxiv</a>.','3. LAMM dataset released on <a href="https://huggingface.co/datasets/openlamm/LAMM_Dataset" target="_blank">Huggingface</a> & <a href="https://opendatalab.com/LAMM/LAMM" target="_blank">OpenDataLab</a> for Research community!',"4. LAMM code is available for Research community!"]}];function S({month:e,content:t}){return n.createElement("div",{className:"flex flex-col p-1"},n.createElement("h4",{className:"mb-1 font-semibold"},"\ud83d\udcc6 [",e,"]"),t.map(((e,t)=>n.createElement("p",{key:t,className:"mb-0 text-lg text-text-400",dangerouslySetInnerHTML:{__html:e}}))))}function Z(){return n.createElement("section",{className:"no-underline-links mt-14 mx-auto flex w-full max-w-5xl flex-col p-4 py-0 md:flex-row md:gap-0"},n.createElement("div",{className:"flex-1"},n.createElement("div",{className:"mb-8 flex items-center justify-between"},n.createElement("h3",{className:"m-0"},"News")),n.createElement("div",{className:"flex flex-col gap-4"},D.map((e=>n.createElement(S,A(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){P(e,t,a[t])}))}return e}({},e),{key:e.month})))))))}function I(){return n.createElement(r.Z,{description:"Real-time audio & video SDKs, ready to launch \ud83d\ude80",wrapperClassName:"homepage flex flex-col",noFooter:!0},n.createElement(x.Z,null,n.createElement("link",{rel:"prefetch",href:"/assets/css/elements.min.css"})),n.createElement(f,null),n.createElement(Z,null),n.createElement(N,null),n.createElement(L,null),n.createElement(h.Z,null),n.createElement(y.Z,null))}}}]);