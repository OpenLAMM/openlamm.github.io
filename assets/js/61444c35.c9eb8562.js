"use strict";(self.webpackChunkdyte_docs=self.webpackChunkdyte_docs||[]).push([[6864],{7778:(e,t,n)=>{n.d(t,{Z:()=>s});var a=n(7294),i=n(1984),r=n(4843);const l=e=>"arxiv"===e.logo?a.createElement(r.ArxivPdf,null):"code"===e.logo?a.createElement(r.GitHubCode,null):a.createElement(r.MachineLearningIcon,null),o=e=>a.createElement("span",{className:"paper_list_top_icon"},a.createElement(i.Z,{to:e.link},a.createElement(l,{logo:e.logo}),e.text));function s(e){return a.createElement("div",{style:{display:"flex",justifyContent:"center",alignItems:"center",marginTop:"0.75rem",marginBottom:"0.75arem"}},a.createElement("div",null,a.createElement(o,{logo:"arxiv",text:"ArXiv",link:e.arxiv_link})),a.createElement("div",{style:{paddingLeft:"0.8rem"}},a.createElement(o,{logo:"code",text:"Code",link:e.code_link})),e.model_zoo_link&&a.createElement("div",{style:{paddingLeft:"0.8rem"}},a.createElement(o,{logo:"model",text:"Model Zoo",link:e.model_zoo_link})))}},8788:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>u,default:()=>m,frontMatter:()=>s,metadata:()=>c,toc:()=>p});n(7294);var a=n(3905),i=n(7778);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})),e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}const s={},u=void 0,c={type:"mdx",permalink:"/paper_list/Octavius",source:"@site/src/pages/paper_list/Octavius.mdx",description:"Octavius: Mitigating Task Interference in MLLMs via MoE",frontMatter:{}},p=[{value:"Introduction",id:"introduction",level:2},{value:"Usage",id:"usage",level:2},{value:"Citation",id:"citation",level:2},{value:"License",id:"license",level:2}],d={toc:p};function m(e){var{components:t}=e,n=o(e,["components"]);return(0,a.kt)("wrapper",l(function(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},a=Object.keys(n);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),a.forEach((function(t){r(e,t,n[t])}))}return e}({},d,n),{components:t,mdxType:"MDXLayout"}),(0,a.kt)("br",null),(0,a.kt)("div",{align:"center",style:{fontSize:"24px"}},(0,a.kt)("b",null,"Octavius: Mitigating Task Interference in MLLMs via MoE")," ",(0,a.kt)("br",null)),(0,a.kt)("div",{align:"center"},"Zeren Chen",(0,a.kt)("sup",null,"1,2*"),"\u2003 Ziqin Wang",(0,a.kt)("sup",null,"1,3*"),"\u2003 Zhen Wang",(0,a.kt)("sup",null,"2*"),"\u2003 Huayang Liu",(0,a.kt)("sup",null,"2"),(0,a.kt)("br",null),"Zhenfei Yin",(0,a.kt)("sup",null,"1,4"),"\u2003 Si Liu",(0,a.kt)("sup",null,"3"),"\u2003 Lu Sheng",(0,a.kt)("sup",null,"2\u2020"),"\u2003 Wanli Ouyang",(0,a.kt)("sup",null,"1,4"),"\u2003 Yu Qiao",(0,a.kt)("sup",null,"1"),"\u2003 Jing Shao",(0,a.kt)("sup",null,"1\u2020")),(0,a.kt)("div",{align:"center"},(0,a.kt)("sup",null,"1"),"Shanghai AI Laboratory\u2003",(0,a.kt)("sup",null,"2"),"School of Software, Beihang University",(0,a.kt)("br",null),(0,a.kt)("sup",null,"3"),"Institute of Artifical Intelligence, Beihang University\u2003",(0,a.kt)("sup",null,"4"),"University of Sydney",(0,a.kt)("br",null),(0,a.kt)("sup",null,"*")," Equal Contribution\u2003",(0,a.kt)("sup",null,"\u2020")," Corresponding Author"),(0,a.kt)(i.Z,{arxiv_link:"https://arxiv.org/abs/2311.02684",code_link:"https://github.com/OpenGVLab/LAMM",model_zoo_link:"/tutorial/training#octavius-model-zoo",mdxType:"PaperListButton"}),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"We propose ",(0,a.kt)("strong",{parentName:"p"},"Octavius"),", a unified, multimodal large language with a novel capability to comprehend various tasks across different modalities, including but not limited to 2D captioning, 2D detection, 3D VQA, and 3D dense captioning. Through combining well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, ",(0,a.kt)("em",{parentName:"p"},"i.e."),", LoRA, Octavius can efficiently be involved in more downstream tasks and more modalities by learning more LoRA modules, alleviating the potential task interference issuse arise from multimodal learning."),(0,a.kt)("img",{src:"/logo/Octavius_arch.png"}),(0,a.kt)("br",null),(0,a.kt)("h2",{id:"usage"},"Usage"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Environment ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/installation#training"},"installation"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Prepare the ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/datasets/instruction"},"instruction")," / ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/datasets/benchmark"},"benchmark")," dataset and required ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/training#prepare-required-checkpoints"},"pretrained weights")," for LLMs and visual encoder.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Training scripts:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Image modality only"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd src\nsh tools/Octavius/train_octavius_slurm.sh <YOUR_PARTITION>  <NUM_GPU> \\\n    config/Octavius/octavius_2d_e4_bs64.yaml octavius_2d_e4_bs64\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Point cloud modality only"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd src\nsh tools/Octavius/train_octavius_slurm.sh <YOUR_PARTITION>  <NUM_GPU> \\\n    config/Octavius/octavius_3d_e3_bs64.yaml octavius_3d_e3_bs64\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Image & point cloud modality joint"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd src\nsh tools/Octavius/train_octavius_slurm.sh <YOUR_PARTITION>  <NUM_GPU> \\\n    config/Octavius/octavius_2d+3d_e6_bs64.yaml octavius_2d +3d_e6_bs64\n")))),(0,a.kt)("p",{parentName:"li"},"We provide pretrained Octavius model ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/training#octavius-model-zoo"},"here"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Evaluation"),(0,a.kt)("p",{parentName:"li"},"We use ChEF to evaluate Octavius on both image and point cloud modalities, see ",(0,a.kt)("a",{parentName:"p",href:"/tutorial/benchmark/default#lamm-benchmark"},"here")," for details."))),(0,a.kt)("h2",{id:"citation"},"Citation"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bibtex"},"@misc{chen2023octavius,\n      title={Octavius: Mitigating Task Interference in MLLMs via MoE}, \n      author={Zeren Chen and Ziqin Wang and Zhen Wang and Huayang Liu and Zhenfei Yin and Si Liu and Lu Sheng and Wanli Ouyang and Yu Qiao and Jing Shao},\n      year={2023},\n      eprint={2311.02684},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n")),(0,a.kt)("h2",{id:"license"},"License"),(0,a.kt)("p",null,"The project is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes."))}m.isMDXComponent=!0}}]);